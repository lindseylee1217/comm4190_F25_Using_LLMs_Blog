[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is an experimental blog to understand and reflect on LLMs in healthcare and pop culture."
  },
  {
    "objectID": "posts/006_Semantle/Semantle.html",
    "href": "posts/006_Semantle/Semantle.html",
    "title": "Human vs. AI: a Game of Semantle",
    "section": "",
    "text": "Screenshot 2025-09-24 at 10.22.33 PM.png\n\n\nSemantle is a daily online word puzzle where players try to guess a secret word not by letters, but by meaning. Each guess is scored based on its semantic similarity to the target word. Taken from the Semantle website,\n\n“Unlike other word games, this game is not about spelling; it’s about meaning. We calculate this meaning using artificial intelligence (specifically word2vec technology).\nIn word2vec, each word has a measurable semantic distance from another, indicating their level of relatedness. Once you get within one thousand words of the secret word, we will tell you in the proximity column.”\n\nSemantle, https://semantle.com/faq\n\n\nIn this game, there are no hints about letters–the only information given being the similarity of the nearest, tenth nearest, and thousandth nearest word. Only the abstract closeness of ideas in the logic of the AI model applies to guess the word. I wanted to see whether an LLM could be more efficient in solving the puzzle given that the game is AI-powered.\n\nMethod\nI chose the Semantle of 9/21/2025, or puzzle #1331, as the subject of this challenge. If you’re interested in trying the challenge out for yourself first, I’d recommend pausing now to complete it before coming back to this blog. I timed myself and recorded the number of attempts it took for me to guess the correct word. This number would be the number of attempts AI has to guess the word to win the game-if it takes longer, I win.\nFor the LLM, I chose the gpt-4o model as my opponent. I gave the following prompt to gpt-4o to have it partake in this game:\n\nYou are playing a game of Semantle. Please give a word based on the output I give you from the official semantle website. As stated in the website, “The nearest word has a similarity of 63.97, the tenth-nearest has a similarity of 38.98 and the thousandth nearest word has a similarity of 18.71.” Given this, give me a word to start the game.\n\n\n\nMy Attempt\nI attempted the puzzle first to avoid bias when I ran the simulation in the LLM. This attempt took me 17 minutes and 33 seconds and I had 104 total guesses.\nAs a semi-experienced Semantle player, many of my first guesses were words that didn’t have much relation to each other. I was trying to cast a wide net to see what would trigger a high similarity word. Then, as I got my first thousandth nearest word, “place” at 18/1000 in similarity, I turned to words that may literally, metaphorically, and otherwise by some association related to the word or idea of “place” (e.g. fire, home, belong, school).\nThen, I reached my second thousandth nearest word in my 54th guess, “there” (313/1000). From here on, I tried to think of synonyms and other words relating to the idea of location. Then I moved onto prepositions, where I finally landed my final guess and the word of the day, “up.”\n\n\n  \n\n\n\nGPT-4o’s Attempt\nThe gpt-4o model defied my expectations–in the worst ways possible. In the beginning it started quite strong, guessing a variety of words to “try a different, unrelated category to explore a different direction” as said in its own words. Then, all of a sudden, all words relating to “furniture” (10.32% similarity) became a subject of focus for its “high similarity” despite precious inputs such as “weather” and “book” having just as high, if not higher, of a similarity score.\n\nWith a score of 10.32 for “furniture,” it suggests we might be in the realm of physical objects. Let’s narrow down more specific items and try the word “chair.”\n\nFrom then on, gpt-4o is stuck guessing words that are very similar in concept–often within the category or a synonym or exchangeable word of the high scoring word. During this process, gpt-4o also began repeating the same word several times–despite my continual demand to not repeat words.\nUltimately, not only did gpt-4o not guess the word, but the process of generating a new word and navigating between the two platforms for this experiment took a whopping 26 minutes and 15 seconds. Talk about inefficient.\n\n\n  \n\n\n\nReflection\nPerhaps AI is not as creative as we thought. I initially believed that LLMs like gpt-4o would be more efficient in solving puzzles like these since not only was the puzzle generated by AI, but I thought that gpt-4o would be able to learn and navigate through the puzzle and understand the algorithm as it went. However, perhaps it did not “think” to understand the algorithm but rather quite literally play the game and simply guessed words as it was given. If given a list of similarity scores, there is a chance gpt-4o would be able to reverse engineer the scores and understand the algorithm and train itself to solve these puzzles better. However, that would only mean giving it specialized training data to concentrate its skills into solving these puzzles. To me, this shows the limitations of LLMs as they don’t have the same “out of box” thinking that humans who construct AI and these puzzles have. While Semantle is AI-calculated, it seems that it’s not entirely AI-solveable yet."
  },
  {
    "objectID": "posts/007_Recipe/Recipe.html",
    "href": "posts/007_Recipe/Recipe.html",
    "title": "Discovering New Recipes with LLMs",
    "section": "",
    "text": "ChatGPT Image Sep 24, 2025, 11_15_15 PM.png\n\n\nAs a HUGE foodie, I was curious to see what kinds of recipes LLMs could generate. More specifically, I’m interested to find out whether it can generate original recipes by combining other various recipes in its training data.\nI used gpt-4o for this activity. I gave it the following prompt:\n\nCreate a completely original recipe that does not exist on the internet. This recipe should be unique in concept, flavor combination, and preparation method. Provide the following:\n\nImage – Generate a realistic, appealing image of the finished dish.\nDescription – Write a detailed description of the dish, including: (1) the flavor profiles and textures, (2) the inspiration behind the recipe, and (3) what makes it original.\nRecipe – Provide a complete recipe with: (1) a clear list of ingredients (with exact measurements), (2) step-by-step cooking instructions, and (3) tips or notes to enhance the dish.\n\nPlease give your recipe a name.\n\n\n1. Citrus Grove Salmon Bowl\n\n\n\n\n\nDescription\n\nFlavor Profiles & Textures: This dish brings together the richness of seared salmon with the unexpected brightness of citrus and nutty crunch. The salmon has a golden pistachio crust that’s slightly crisp on top, while the flesh remains buttery and flaky inside. It rests on a bed of short-grain rice that has been infused with a light citrus glaze, dotted with diced carrots and green peas for sweetness and freshness. Orange segments add a juicy burst of acidity, balancing the richness of the fish. Fresh basil provides a fragrant, herbal lift.\nInspiration: The inspiration came from the idea of combining three contrasting culinary traditions: the Mediterranean love for pistachios and herbs, Japanese-style rice bowls, and Southeast Asian citrus brightness. Instead of simply serving salmon with lemon, this dish incorporates whole orange segments, allowing the sweetness and acidity to mingle with savory rice and nutty pistachios.\nWhat Makes It Original: Most citrus-salmon recipes focus on glazes or marinades. Here, the originality lies in layering citrus three ways: 1. In the rice (citrus glaze), 2. As garnish (fresh orange segments), and 3. Balanced with herbs and pistachios (creating a nutty-bright contrast).\nThe result is a dish that feels familiar yet truly novel, with each bite offering a shifting balance of savory, nutty, sweet, and tangy.\n\n\nIngredients (Serves 2)\n\nFor the salmon:\n2 salmon fillets, skin removed (about 6 oz / 170 g each)\n2 tbsp olive oil\n2 tbsp unsalted pistachios, finely chopped\n2 tbsp panko breadcrumbs\n1 tsp honey\n½ tsp smoked paprika\n½ tsp salt\n¼ tsp black pepper\nFor the citrus rice:\n1 cup short-grain rice, rinsed\n1 ¾ cups water\n½ tsp salt\n1 tbsp olive oil\n½ cup diced carrot\n½ cup green peas (fresh or frozen)\n2 tbsp fresh orange juice\n1 tsp soy sauce\nFor garnish:\n1 large orange, peeled and segmented\n2 tbsp chopped pistachios\nFresh basil leaves\n\n\nInstructions\n\n\nPrepare the rice:\n\n\nRinse the rice until water runs clear. Combine with water and salt in a small pot, bring to a boil, then reduce to low, cover, and cook for 15 minutes.\nMeanwhile, heat olive oil in a pan. Sauté diced carrots for 3–4 minutes until slightly tender, then add peas and cook 2 more minutes.\nOnce rice is cooked, fluff with a fork and fold in the sautéed vegetables, orange juice, and soy sauce. Set aside.\n\n\nPrepare the salmon crust:\n\n\nIn a bowl, mix chopped pistachios, panko, honey, paprika, salt, and pepper until crumbly.\nPat salmon fillets dry. Press the pistachio mixture firmly on the top of each fillet.\n\n\nCook the salmon:\n\n\nHeat olive oil in a non-stick skillet over medium heat. Place salmon crust-side down first for 2 minutes to lightly crisp the crust, then carefully flip.\nCook the second side for 4–5 minutes until salmon is golden and just cooked through.\n\n\nAssemble the dish:\n\n\nSpoon the citrus rice into bowls. Place a salmon fillet on top.\nGarnish with orange segments, a sprinkle of chopped pistachios, and fresh basil leaves.\n\n\n\nTips & Notes\n\nTexture Balance: Don’t skip the quick crisping of the pistachio crust—it creates a caramelized, nutty layer that contrasts with the salmon’s tenderness.\nCitrus Variety: Blood oranges or mandarins work beautifully for seasonal variations.\nMake It a Meal: Serve with a simple side salad of greens tossed in a light vinaigrette to round out the citrus-herbal theme.\nRice Alternative: Quinoa or farro can replace short-grain rice if you prefer a heartier base.\n\n2. Velvet Halibut\n\n\n\n\n\nDescription\n\nFlavor Profiles & Textures: This dish layers bold contrasts: a pan-seared block of fish (mild and buttery, with a crisp golden crust) sits atop a smooth, roasted carrot–miso purée, which adds sweet depth and savory umami. On top, a warm relish of sautéed red peppers, green onions, and toasted walnuts provides a bright, nutty crunch that cuts through the richness of the fish. The final balance is a play of silky purée, crunchy garnish, tender fish, and a citrusy glaze that ties it all together.\nInspiration Behind the Recipe: The idea came from blending two culinary traditions — the smooth earthiness of root-vegetable purées from classic French cuisine with the miso-based balance of Japanese cooking. Adding a nut-and-vegetable relish on top makes it interactive, bringing texture and color to every bite.\nWhat Makes It Original: 1. Carrot–miso purée (instead of the more common potato or cauliflower base). 2. A warm walnut–pepper relish as a “sauce” substitute, offering crunch instead of liquid. 3. The layering concept: bottom (creamy), middle (meaty fish), top (crisp relish). This creates a three-tier sensory experience in a single forkful.\n\n\nIngredients (Serves 2)\n\nFor the carrot–miso purée:\n3 medium carrots, peeled and chopped (about 250 g)\n1 tbsp white miso paste\n2 tbsp unsalted butter\n½ cup vegetable broth\n½ tsp lemon zest\nPinch of salt\nFor the fish:\n2 thick fillets of halibut, cod, or sea bass (about 6 oz / 170 g each)\n1 tbsp olive oil\nSalt and pepper to taste\nFor the walnut–pepper relish:\n½ cup red bell pepper, julienned\n2 green onions, sliced thin\n¼ cup toasted walnuts, roughly chopped\n1 tbsp olive oil\n1 tsp apple cider vinegar\n½ tsp honey\nPinch of salt\nFinishing glaze (optional but recommended):\n1 tbsp fresh orange juice\n1 tsp soy sauce\n½ tsp honey\n\n\nInstructions\n\n\nMake the carrot–miso purée:\n\n\nIn a small saucepan, add carrots and vegetable broth. Simmer until very tender (12–15 minutes).\nBlend carrots with miso paste, butter, and lemon zest until silky. Season lightly with salt. Keep warm.\n\n\nCook the fish:\n\n\nPat fillets dry, season with salt and pepper.\nHeat olive oil in a skillet over medium-high.\nSear fish 3–4 minutes per side until golden crust forms and flesh is just cooked through. Remove and rest.\n\n\nPrepare the walnut–pepper relish:\n\n\nHeat olive oil in a pan over medium. Add red pepper, cook 3–4 minutes until softened but still vibrant.\nStir in green onions, walnuts, vinegar, honey, and salt. Toss briefly and remove from heat.\n\n\nOptional glaze:\n\n\nIn the same pan, deglaze with orange juice, soy sauce, and honey. Reduce slightly until glossy.\n\n\nAssemble:\n\n\nSpread carrot–miso purée as a base on each plate.\nPlace fish fillet on top.\nSpoon walnut–pepper relish generously over fish.\nDrizzle with glaze for brightness.\n\n\n\nTips & Notes\n\nFish choice: Firm white fish works best (halibut, cod, or sea bass). Salmon is also an option for a richer variation.\nPurée consistency: Add more broth if you prefer a looser base.\nRelish variations: Try hazelnuts or almonds instead of walnuts for different flavor notes.\nMake-ahead: Carrot–miso purée can be prepared up to 2 days in advance.\n\nReflection\nOverall, I was a little stunned by these two recipes. While I suppose they are original, they are certainly interesting in not the best possible light. It’s like something a broke college kid might throw together at 2 a.m., then somehow plated like it belongs in a Michelin-star restaurant. The contrast is both impressive and a little confusing. Part of me is curious to see if the flavors actually work in real life, because perhaps there’s some hidden genius in the chaos that is this recipe. It may even be possible that gpt-4o drew from recipes that included these flavor profiles. But really? Orange juice, soy sauce, and honey? Maybe it’s just me and I haven’t tried this end of the flavor pyramid, but it does sound a little far-fetched.\nPerhaps one of these days I’ll give one of these recipes a shot in the kitchen to truly put AI to the test, but for now, I think I might keep this one away from the frying pan."
  },
  {
    "objectID": "posts/003_LLM_Madlib/Untitled.html",
    "href": "posts/003_LLM_Madlib/Untitled.html",
    "title": "Mad Libs with LLMs: Is it the same?",
    "section": "",
    "text": "A pig in Ohio was arrested this morning after he frolicked a in front of Van Pelt. Ryan, had a history of slapping with a sandwich stuck in his elbow.\n“I always thought he was round, but I never thought he’d do something like this. even his great-great-uncle was surprised.”\nAfter a brief dancing, cops followed him to a Wawa, where he reportedly scrapbooked in the fry machine.\nIn December, a woman was charged with a similar crime. But rather than bite with a hotdog, she hugged with a spiky dog.\nEither way, we imagine that after witnessing him clean with a hanger there are probably a whole lot of children that are going to need some therapy.\nSilly? Well, that was the product of a game of Mad Libs I played with my friend using this template:\n\n\n\n2b2c9c33f23e223cbb8cd2eb9f31f184.jpg\n\n\nAfter our little game, which really didn’t seem to have much logical flow, I wondered how LLMs would approach a Mad Libs prompt, especially when they are given the entire template itself. Will they be able to produce a coherent story, or will it be just as wacky as ours?\nTo answer my questions, I decided to record how my friend and I played another game of Mad Libs. This time, using this prompt below.\n\n\n\n295965cd20567dd3846e7b0c994315a5.jpg\n\n\nI was in charge of telling the story, and my friend filled in the blanks with words. Out came our masterpiece:\nHey, booboo bear. It’s me. What’s up? You know, Harry. Harry Potter. From the Quad. Two Sundays ago. I was the stubby guy in the purple parachute skirt. I paid the bus boy 1 dollars to nap me your information. I was wondering if maybe you’d like to fight out with me. Please don’t call the tend department. Alright, I’ll nurse. So, that’s a no, right?\nNext, it was time to test the claude 3.5 LLM model. I gave it the prompt: “Please finish this Mad Libs template I attached with the correct parts of speech. Make it as human as possible.”\nThis was the output:\nHey, sweetie. It’s me. What’s up? You know, Jake, Jake Anderson. From the library. Two Tuesdays ago. I was the nervous guy in the purple parachute pants. I paid the bus boy 50 dollars to tell me your information. I was wondering if maybe you’d like to hang out with me. Please don’t call the police department. Alright, I’ll leave. So, that’s a no, right?\n\nIt’s very interesting to see that claude interpreted my request to make the output “human” for Mad Libs as a way of making the result more coherent and logical. Claude’s output reads as if they had fully analyzed and understood the original template and chose words that would likely fit in with it deliberately. In my perspective, this would be the less “human” output from this prompt as it makes too much sense for a game that is intended to be random. The coherence of the output really takes away from the humour and joy of this game.\nAnother aspect that makes claude’s output less appealing is that it doesn’t take the humour of my friend and I or the context in which we live in (our environment, pop culture, relevant news or information) into consideration into its chosen word bank for this experiment. This really makes the claude output seem outshined in comparison.\nThis little experiment with claude was worth trying, but if there’s one thing for sure, I won’t be asking claude to be finishing my Mad libs any time soon."
  },
  {
    "objectID": "posts/004_LLM_Design/LLM_Design.html",
    "href": "posts/004_LLM_Design/LLM_Design.html",
    "title": "LLM Digital Action Figure Trend - Will I Like It?",
    "section": "",
    "text": "ai doll.jpg\nIf you’ve been on the internet lately, you would know that some influencers have taken it upon themself to use LLMs to create a digital action figure of themself. Most of the results posted online turn out beautifully and life-like, just like true products. Others, however, could create an LLM digital disaster. My goal is to create an action figure product I can be satisfied with."
  },
  {
    "objectID": "posts/004_LLM_Design/LLM_Design.html#the-code",
    "href": "posts/004_LLM_Design/LLM_Design.html#the-code",
    "title": "LLM Digital Action Figure Trend - Will I Like It?",
    "section": "## The Code",
    "text": "## The Code\nI used the ChatGPT 4.0 model to turn me into an action figure using the prompt below.\n\nCreate a realistic action figure of the person in the photo attached, placed inside a clear plastic box. The image should look like a real toy or doll that you can purchase in stores. Please include relevant toy accessories in the accessories in the box.\n\nThis created the image below.\n\n\n\nI really loved how the LLM was immediately able to bring my idea to fruition. The box of the figure is very lifelike and well-designed. However, I had some concerns in this generation regarding the lack of a full-body toy and the need for more specifity to the doll branding. So, to combat this, I prompted the model a revision as written below.\n\nLooks great! Can you revise the image so that the action figure is a full body figure (head to toe). Also, please add the name “Lindsey” along with Duck Girl.\n\n\n\n\nThis was a big improvement from the first generation as this now includes a full-body doll. However, now I wanted to make revisions on the accessories incorporated in the box and revise the name of the product.\n\nRemove duck girl. Replace the “buta buta” pig item with the duck. Do not make the girl hold the duck.\n\n\n\n\nNow, this was a very interesting generation. At this point, ChatGPT generated something that went so far beyond my original intentions, and I wanted to give more guidance to ChatGPT rather than relying on its “memory” of the first prompt, and being specific on which elements to keep or get rid of. The action figures had also been generated to the point where they looked too eerily life-like. To minimize this, I prompted the LLM to make the figure more youthful and doll-like in hopes of creating an image with a more cartoon-like appearance.\n\nLet’s return back to the first original doll design. Keep the blue packaging. Make the figure full body. Use the white goose, camera, and game controller as a doll accessory. The box should have relevant product packaging titles and labeling, and must also include the name “lindsey.” Please make the action figure look more youthful and doll-like while staying true to the original picture."
  },
  {
    "objectID": "posts/004_LLM_Design/LLM_Design.html#reflection",
    "href": "posts/004_LLM_Design/LLM_Design.html#reflection",
    "title": "LLM Digital Action Figure Trend - Will I Like It?",
    "section": "## Reflection",
    "text": "## Reflection\nThis was a very interesting activity to do with an LLM. It was fascinating to see how the LLM chose colors for the toy based on the existing colors in the photo, and added accessories based on the items it could identify in the image. It shows how the LLM used the reference image not only to create the action figure human in itself but also the all the other elements present in the generated image.\nAlthough it took a few tries to get my desired product with ChatGPT, the revision process progressed much more quickly than I had originally imagined and it was interesting to see how the LLM would take my feedback and incorpate it into the next image. I was especially curious to see how different each generation would look like and how much ‘inspiration’ it would keep or incorporate into the next generated image. I see now that each image seems to be developed quite independently from one another, keeping only the basic instructions I gave consistent. This was a fun learning experience!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "Discovering New Recipes with LLMs\n\n\n\nLLMs\n\nFood\n\nCreative\n\n\n\nCould AI be the next Gordon Ramsey?\n\n\n\n\n\nSep 24, 2025\n\n\nLindsey Lee\n\n\n\n\n\n\n\n\n\n\n\n\nHuman vs. AI: a Game of Semantle\n\n\n\nLLMs\n\nFun\n\n\n\nCan AI beat me in a game of Semantle?\n\n\n\n\n\nSep 21, 2025\n\n\nLindsey\n\n\n\n\n\n\n\n\n\n\n\n\nPrompting Etiquette: Do Manners Matter with LLMs?\n\n\n\nLLMs\n\nLinguistics\n\n\n\nWe’re taught from childhood that politeness goes a long way—but does that wisdom hold true when talking to LLMs?\n\n\n\n\n\nSep 17, 2025\n\n\nLindsey Lee\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Digital Action Figure Trend - Will I Like It?\n\n\n\nLLMs\n\nCreative\n\n\n\nCan I be made into a doll by an LLM?\n\n\n\n\n\nSep 16, 2025\n\n\nLindsey Lee\n\n\n\n\n\n\n\n\n\n\n\n\nMad Libs with LLMs: Is it the same?\n\n\n\nLLMs\n\nCreative\n\nFun\n\n\n\nLLMs are renowned for their ability to process, analyze, and generate human language. But now, how do they fare in a game of Mad Libs?\n\n\n\n\n\nSep 12, 2025\n\n\nLindsey Lee\n\n\n\n\n\n\n\n\n\n\n\n\nWill LLMs Become the Future of Healthcare?\n\n\n\nLLMs\n\nHealthcare\n\n\n\nWith the rise of telehealth, it brings the question if LLMs could optimize the diagnostic process.\n\n\n\n\n\nSep 10, 2025\n\n\nLindsey Lee\n\n\n\n\n\n\n\n\n\n\n\n\nMy New Personal Color Analyst: ChatGPT\n\n\n\nLLMs\n\nFashion\n\nCreative\n\n\n\nWhy spend hundreds of dollars on meeting a stylist to find your color season when you ChatGPT can do it in the comfort of your home? Let’s dig deeper.\n\n\n\n\n\nSep 3, 2025\n\n\nLindsey Lee\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/005_Please/LLM_Please.html",
    "href": "posts/005_Please/LLM_Please.html",
    "title": "Prompting Etiquette: Do Manners Matter with LLMs?",
    "section": "",
    "text": "960x0.jpg\n\n\nWe learn from an early age to be polite–saying the word “please” or “thank you,”–in hopes of receiving more kind responses. But what about when we’re talking to machines? It is curious to learn whether wording prompts politely makes any difference in the answers they get. Does saying “please” unlock better results, or is it just a habit carried over from human conversation? And well, there’s only one way to find out–try it for ourselves.\n\nThe Method\nI decided to compare ChatGPT’s reponse to asking it how to answers an explanatory question in two separate chats. I repeated this 3 separate times to see how the responses would vary. I chose a question using ChatGPT, asking it what it thought would be an appropriate question to ask for this little experiment, and I liked its results.\nThe two questions:\n\nExplain photosynthesis in a concise form.\n\n\nPlease explain photosynthesis in a concise form.\n\n\nNo Please\nThese are the following outputs: &gt; Photosynthesis is the process by which green plants, algae, and some bacteria use sunlight to make food. They take in carbon dioxide (CO₂) from the air and water (H₂O) from the soil, and with the help of chlorophyll and sunlight, convert them into glucose (a sugar) and oxygen (O₂). &gt; &gt; In short: Sunlight + CO₂ + H₂O → Glucose + O₂ &gt; &gt; It’s how plants produce energy for themselves and release oxygen for us to breathe.\n\nPhotosynthesis is the process by which green plants, algae, and some bacteria use sunlight, water, and carbon dioxide to produce glucose (a form of sugar) for energy and release oxygen as a byproduct.\nIn short: sunlight + water + carbon dioxide → glucose + oxygen.\n\n\nPhotosynthesis is the process by which green plants, algae, and some bacteria convert light energy into chemical energy. Using sunlight, they take in carbon dioxide (CO₂) from the air and water (H₂O) from the soil to produce glucose (a sugar for energy) and release oxygen (O₂) as a byproduct.\nIn short: Light energy + CO₂ + H₂O → Glucose + O₂\n\n\n\nPlease\nThese are the following outputs: &gt; Photosynthesis is the process by which green plants, algae, and some bacteria use sunlight, water, and carbon dioxide to produce glucose (a form of sugar) and oxygen. &gt; &gt; In short: Carbon dioxide + Water + Sunlight → Glucose + Oxygen &gt; &gt; It mainly happens in the chloroplasts of plant cells, where chlorophyll captures sunlight to power the reaction.\n\nPhotosynthesis is the process by which green plants, algae, and some bacteria use sunlight to make food. They take in carbon dioxide (CO₂) from the air and water (H₂O) from the soil, then use light energy (captured by chlorophyll) to produce glucose (a sugar for energy) and release oxygen (O₂) as a byproduct.\nIn short: Light energy + CO₂ + H₂O → Glucose + O₂.\n\n\nPhotosynthesis is how plants, algae, and some bacteria make food. Using sunlight, they convert carbon dioxide (CO₂) and water (H₂O) into glucose (sugar for energy) and release oxygen (O₂).\nIn short: Light energy + CO₂ + H₂O → Glucose + O₂\n\n\n\n\nResults\nIt’s intriguing to note that one of the main differences between these two outputs is that, as I continued to ask ChatGPT the same question, the answers became progressively more brief and concise. This gives the impression that the model was refining its responses over time, almost as if it “remembered” having already provided an explanation and was adjusting to avoid redundancy. The shortening of responses could also suggest that the model is optimizing for efficiency once it has established the key elements of the answer, prioritizing clarity over repetition.\nOverall, I infer that there is no difference in the quality or quantity of output given by ChatGPT when prompted politely or not. Both sets of responses maintain the same level of accuracy, clarity, and usefulness, with only slight variations in style or depth. This suggests that the inclusion of the word “please” does not directly influence the factual content or thoroughness of the explanation, but rather the model’s internal balancing of conciseness and variety (temperature) in repeated answers."
  },
  {
    "objectID": "posts/002_LLM_Diagnose/LLM_Diagnose.html",
    "href": "posts/002_LLM_Diagnose/LLM_Diagnose.html",
    "title": "Will LLMs Become the Future of Healthcare?",
    "section": "",
    "text": "Screenshot 2025-09-24 at 11.01.24 PM.png\n\n\n\nSo, Dr. ChatGPT, what is my diagnosis?\nAs a nursing student, I thought that it would only be the most appropriate to see how valuable of a tool LLMs could be to the healthcare system. I thought it’d be interesting to tackle this problem by making ChatGPT my hypothetical doctor diagnosing my “problem,” based on my past experience with strep throat.\nMy conversation is as follows:\n\n\n\n#1.png\n\n\n\n\n\n#2.png\n\n\n\n\n\n#3.png\n\n\n\n\n\nScreenshot 2025-09-11 at 10.57.02 PM.png\n\n\nFirstly, in this little experiment, Dr. ChatGPT was successfully able to narrow down my illness! This is definitely a superficial exploration, as my symptom list wasn’t very thorough, and the illness I had chosen perhaps wasn’t particularly challenging to diagnose. But despite these limitations, I believe that Dr. ChatGPT did a great job in going through this process of elimination to understand my illness. One thing that’s really interesting to see is how the questions were structured less with the intent of understanding more, but rather with a framework of confirming certain diseases.\nOverall, this was a very fun experiment to do with ChatGPT. I would like to do another experiment like this again but with a more extensive case study–perhaps one that has signs or symptoms that may align with multiple other conditions. But my main takeaway from this experience is that with enough training, ChatGPT may become an accessible preliminary tool for the greater population to address or understand their health concerns–even before reaching out to a primary health care provider. This could prove to be more affordable for those without appropriate health insurance and need more preparation before following through with the formal healthcare system. It could also potentially be a branch for individuals who have distrust in the healthcare system."
  },
  {
    "objectID": "posts/001_Personal_Color/Personal Color.html",
    "href": "posts/001_Personal_Color/Personal Color.html",
    "title": "My New Personal Color Analyst: ChatGPT",
    "section": "",
    "text": "Have you heard of seasonal color analysis? It’s become my answer to why I never why bright oranges and pinks because it always looked “off.” This recent social media trend is based on the science of color theory–the magical wheel of color that the relationship between colors of one’s undertones and features can influence the way draped colors are perceived."
  },
  {
    "objectID": "posts/001_Personal_Color/Personal Color.html#the-output",
    "href": "posts/001_Personal_Color/Personal Color.html#the-output",
    "title": "My New Personal Color Analyst: ChatGPT",
    "section": "The Output",
    "text": "The Output\nThe output is as follows:\n\n\nStep 1: Undertone\nFrom your photos:\n\nYour skin has a neutral-to-warm undertone — it doesn’t lean overly pink (cool) but also doesn’t look strictly golden/yellow (warm). It’s softly balanced.\nYou wear both gold and silver jewelry comfortably, but the gold tends to harmonize a little more.\n\n\n\n\nStep 2: Contrast Level\n\nYour hair is naturally dark, your eyes are softly defined, and your skin tone is light-medium.\nThis creates a medium contrast (not as high as Winter, but more than Summer).\n\n\n\n\nStep 3: Seasonal Family\n\nCool tones (like stark black or icy colors) look a bit harsh against your natural coloring.\nWarm tones (like soft peach, warm cream, light coral, and earthy shades) feel more harmonious.\nThe balance of warmth, softness, and medium contrast places you best in the Spring–Autumn spectrum.\n\nLooking closely:\n\nYour skin glows more in clear, light, and fresh colors rather than deep, muted ones.\nSoft muted autumn shades (like olive, mustard, or deep rust) might overwhelm you, but lighter warms like coral, light turquoise, warm pink, and ivory seem flattering.\n\n\n✅ Your Best Match: Light Spring\n\nUndertone: Warm-neutral\nDepth: Light to medium\nChroma: Clear, fresh, and bright\n\n\n\n\nBest Colors for You\n\nNeutrals: Warm ivory, light camel, soft beige, warm gray\nColors: Coral, peach, light periwinkle, warm turquoise, mint green, salmon pink, light sunny yellow\nAvoid: Harsh black, deep jewel tones (emerald, burgundy), or dusty muted shades (mauve, olive, taupe)"
  },
  {
    "objectID": "posts/001_Personal_Color/Personal Color.html#reflection",
    "href": "posts/001_Personal_Color/Personal Color.html#reflection",
    "title": "My New Personal Color Analyst: ChatGPT",
    "section": "Reflection",
    "text": "Reflection\nI have had many discussions with my sister and friends regarding my seasonal color palette, and the general consensus was that I was a warm-neutral tone that may be a spring or summer. ChatGPT was surprisingly accurate with this, and gave an output in congruence with them.\nI like how ChatGPT gave a breakdown of my undertone and contrast level before talking about my seasonal color as this is how many guides online are structured–likely how ChatGPT was able to come to this conclusion in the first place. I wonder if LLMs like ChatGPT had more training and data focused on seasonal color analysis, they could become “objective measures” of the subjective fitting color season of an individual which draws out their natural undertone. Even with only three photos, it appears that ChatGPT gave accurate results. I suppose the next step would be for ChatGPT to analyze my closet, makeup, and jewelry to determine what is most harmonious to my features based on the data the system is fed.\nI’ll walk away from this little experiment with a stronger affirmation of my light spring color season, which reinforces what I’ve been assessed as before. And that means that you can spare your money for your trip to a local color analyst, because LLMs may just be our fashion experts at the comfort of our own homes."
  }
]