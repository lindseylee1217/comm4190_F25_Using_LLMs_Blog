[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "A test post\n\n\n\nLLMs\n\nCreative\n\n\n\nCan LLMs tell the difference between dress codes?\n\n\n\n\n\nSep 17, 2025\n\n\nLindsey\n\n\n\n\n\n\n\n\n\n\n\n\nPrompting Etiquette: Do Manners Matter with LLMs?\n\n\n\nLLMs\n\nLinguistics\n\n\n\nWe‚Äôre taught from childhood that politeness goes a long way‚Äîbut does that wisdom hold true when talking to LLMs?\n\n\n\n\n\nSep 17, 2025\n\n\nLindsey Lee\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Digital Action Figure Trend - Will I Like It?\n\n\n\nLLMs\n\nCreative\n\n\n\nCan I be made into a doll by an LLM?\n\n\n\n\n\nSep 16, 2025\n\n\nLindsey Lee\n\n\n\n\n\n\n\n\n\n\n\n\nMad Libs with LLMs: Is it the same?\n\n\n\nLLMs\n\nCreative\n\nFun\n\n\n\nLLMs are renowned for their ability to process, analyze, and generate human language. But now, how do they fare in a game of Mad Libs?\n\n\n\n\n\nSep 12, 2025\n\n\nLindsey Lee\n\n\n\n\n\n\n\n\n\n\n\n\nWill LLMs Become the Future of Healthcare?\n\n\n\nLLMs\n\nHealthcare\n\n\n\nWith the rise of telehealth, it brings the question if LLMs could optimize the diagnostic process.\n\n\n\n\n\nSep 10, 2025\n\n\nLindsey Lee\n\n\n\n\n\n\n\n\n\n\n\n\nMy New Personal Color Analyst: ChatGPT\n\n\n\nLLMs\n\nFashion\n\nCreative\n\n\n\nWhy spend hundreds of dollars on meeting a stylist to find your color season when you ChatGPT can do it in the comfort of your home? Let‚Äôs dig deeper.\n\n\n\n\n\nSep 3, 2025\n\n\nLindsey Lee\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/005_Please/LLM_Please.html",
    "href": "posts/005_Please/LLM_Please.html",
    "title": "Prompting Etiquette: Do Manners Matter with LLMs?",
    "section": "",
    "text": "960x0.jpg\n\n\nWe learn from an early age to be polite‚Äìsaying the word ‚Äúplease‚Äù or ‚Äúthank you,‚Äù‚Äìin hopes of receiving more kind responses. But what about when we‚Äôre talking to machines? It is curious to learn whether wording prompts politely makes any difference in the answers they get. Does saying ‚Äúplease‚Äù unlock better results, or is it just a habit carried over from human conversation? And well, there‚Äôs only one way to find out‚Äìtry it for ourselves.\n\nThe Method\nI decided to compare ChatGPT‚Äôs reponse to asking it how to answers an explanatory question in two separate chats. I repeated this 3 separate times to see how the responses would vary. I chose a question using ChatGPT, asking it what it thought would be an appropriate question to ask for this little experiment, and I liked its results.\nThe two questions:\n\nExplain photosynthesis in a concise form.\n\n\nPlease explain photosynthesis in a concise form.\n\n\nNo Please\nThese are the following outputs: &gt; Photosynthesis is the process by which green plants, algae, and some bacteria use sunlight to make food. They take in carbon dioxide (CO‚ÇÇ) from the air and water (H‚ÇÇO) from the soil, and with the help of chlorophyll and sunlight, convert them into glucose (a sugar) and oxygen (O‚ÇÇ). &gt; &gt; In short: Sunlight + CO‚ÇÇ + H‚ÇÇO ‚Üí Glucose + O‚ÇÇ &gt; &gt; It‚Äôs how plants produce energy for themselves and release oxygen for us to breathe.\n\nPhotosynthesis is the process by which green plants, algae, and some bacteria use sunlight, water, and carbon dioxide to produce glucose (a form of sugar) for energy and release oxygen as a byproduct.\nIn short: sunlight + water + carbon dioxide ‚Üí glucose + oxygen.\n\n\nPhotosynthesis is the process by which green plants, algae, and some bacteria convert light energy into chemical energy. Using sunlight, they take in carbon dioxide (CO‚ÇÇ) from the air and water (H‚ÇÇO) from the soil to produce glucose (a sugar for energy) and release oxygen (O‚ÇÇ) as a byproduct.\nIn short: Light energy + CO‚ÇÇ + H‚ÇÇO ‚Üí Glucose + O‚ÇÇ\n\n\n\nPlease\nThese are the following outputs: &gt; Photosynthesis is the process by which green plants, algae, and some bacteria use sunlight, water, and carbon dioxide to produce glucose (a form of sugar) and oxygen. &gt; &gt; In short: Carbon dioxide + Water + Sunlight ‚Üí Glucose + Oxygen &gt; &gt; It mainly happens in the chloroplasts of plant cells, where chlorophyll captures sunlight to power the reaction.\n\nPhotosynthesis is the process by which green plants, algae, and some bacteria use sunlight to make food. They take in carbon dioxide (CO‚ÇÇ) from the air and water (H‚ÇÇO) from the soil, then use light energy (captured by chlorophyll) to produce glucose (a sugar for energy) and release oxygen (O‚ÇÇ) as a byproduct.\nIn short: Light energy + CO‚ÇÇ + H‚ÇÇO ‚Üí Glucose + O‚ÇÇ.\n\n\nPhotosynthesis is how plants, algae, and some bacteria make food. Using sunlight, they convert carbon dioxide (CO‚ÇÇ) and water (H‚ÇÇO) into glucose (sugar for energy) and release oxygen (O‚ÇÇ).\nIn short: Light energy + CO‚ÇÇ + H‚ÇÇO ‚Üí Glucose + O‚ÇÇ\n\n\n\n\nResults\nIt‚Äôs intriguing to note that one of the main differences between these two outputs is that, as I continued to ask ChatGPT the same question, the answers became progressively more brief and concise. This gives the impression that the model was refining its responses over time, almost as if it ‚Äúremembered‚Äù having already provided an explanation and was adjusting to avoid redundancy. The shortening of responses could also suggest that the model is optimizing for efficiency once it has established the key elements of the answer, prioritizing clarity over repetition.\nOverall, I infer that there is no difference in the quality or quantity of output given by ChatGPT when prompted politely or not. Both sets of responses maintain the same level of accuracy, clarity, and usefulness, with only slight variations in style or depth. This suggests that the inclusion of the word ‚Äúplease‚Äù does not directly influence the factual content or thoroughness of the explanation, but rather the model‚Äôs internal balancing of conciseness and variety (temperature) in repeated answers."
  },
  {
    "objectID": "posts/002_LLM_Diagnose/LLM_Diagnose.html",
    "href": "posts/002_LLM_Diagnose/LLM_Diagnose.html",
    "title": "Will LLMs Become the Future of Healthcare?",
    "section": "",
    "text": "So, Dr.¬†ChatGPT, what is my diagnosis?\nAs a nursing student, I thought that it would only be the most appropriate to see how valuable of a tool LLMs could be to the healthcare system. I thought it‚Äôd be interesting to tackle this problem by making ChatGPT my hypothetical doctor diagnosing my ‚Äúproblem,‚Äù based on my past experience with strep throat.\nMy conversation is as follows:\n\n\n\n#1.png\n\n\n\n\n\n#2.png\n\n\n\n\n\n#3.png\n\n\n\n\n\nScreenshot 2025-09-11 at 10.57.02‚ÄØPM.png\n\n\nFirstly, in this little experiment, Dr.¬†ChatGPT was successfully able to narrow down my illness! This is definitely a superficial exploration, as my symptom list wasn‚Äôt very thorough, and the illness I had chosen perhaps wasn‚Äôt particularly challenging to diagnose. But despite these limitations, I believe that Dr.¬†ChatGPT did a great job in going through this process of elimination to understand my illness. One thing that‚Äôs really interesting to see is how the questions were structured less with the intent of understanding more, but rather with a framework of confirming certain diseases.\nOverall, this was a very fun experiment to do with ChatGPT. I would like to do another experiment like this again but with a more extensive case study‚Äìperhaps one that has signs or symptoms that may align with multiple other conditions. But my main takeaway from this experience is that with enough training, ChatGPT may become an accessible preliminary tool for the greater population to address or understand their health concerns‚Äìeven before reaching out to a primary health care provider. This could prove to be more affordable for those without appropriate health insurance and need more preparation before following through with the formal healthcare system. It could also potentially be a branch for individuals who have distrust in the healthcare system."
  },
  {
    "objectID": "posts/004_LLM_Design/LLM_Design.html",
    "href": "posts/004_LLM_Design/LLM_Design.html",
    "title": "LLM Digital Action Figure Trend - Will I Like It?",
    "section": "",
    "text": "ai doll.jpg\nIf you‚Äôve been on the internet lately, you would know that some influencers have taken it upon themself to use LLMs to create a digital action figure of themself. Most of the results posted online turn out beautifully and life-like, just like true products. Others, however, could create an LLM digital disaster. My goal is to create an action figure product I can be satisfied with."
  },
  {
    "objectID": "posts/004_LLM_Design/LLM_Design.html#the-code",
    "href": "posts/004_LLM_Design/LLM_Design.html#the-code",
    "title": "LLM Digital Action Figure Trend - Will I Like It?",
    "section": "## The Code",
    "text": "## The Code\nI used the ChatGPT 4.0 model to turn me into an action figure using the prompt below.\n\nCreate a realistic action figure of the person in the photo attached, placed inside a clear plastic box. The image should look like a real toy or doll that you can purchase in stores. Please include relevant toy accessories in the accessories in the box.\n\nThis created the image below.\n\n\n\nI really loved how the LLM was immediately able to bring my idea to fruition. The box of the figure is very lifelike and well-designed. However, I had some concerns in this generation regarding the lack of a full-body toy and the need for more specifity to the doll branding. So, to combat this, I prompted the model a revision as written below.\n\nLooks great! Can you revise the image so that the action figure is a full body figure (head to toe). Also, please add the name ‚ÄúLindsey‚Äù along with Duck Girl.\n\n\n\n\nThis was a big improvement from the first generation as this now includes a full-body doll. However, now I wanted to make revisions on the accessories incorporated in the box and revise the name of the product.\n\nRemove duck girl. Replace the ‚Äúbuta buta‚Äù pig item with the duck. Do not make the girl hold the duck.\n\n\n\n\nNow, this was a very interesting generation. At this point, ChatGPT generated something that went so far beyond my original intentions, and I wanted to give more guidance to ChatGPT rather than relying on its ‚Äúmemory‚Äù of the first prompt, and being specific on which elements to keep or get rid of. The action figures had also been generated to the point where they looked too eerily life-like. To minimize this, I prompted the LLM to make the figure more youthful and doll-like in hopes of creating an image with a more cartoon-like appearance.\n\nLet‚Äôs return back to the first original doll design. Keep the blue packaging. Make the figure full body. Use the white goose, camera, and game controller as a doll accessory. The box should have relevant product packaging titles and labeling, and must also include the name ‚Äúlindsey.‚Äù Please make the action figure look more youthful and doll-like while staying true to the original picture."
  },
  {
    "objectID": "posts/004_LLM_Design/LLM_Design.html#reflection",
    "href": "posts/004_LLM_Design/LLM_Design.html#reflection",
    "title": "LLM Digital Action Figure Trend - Will I Like It?",
    "section": "## Reflection",
    "text": "## Reflection\nThis was a very interesting activity to do with an LLM. It was fascinating to see how the LLM chose colors for the toy based on the existing colors in the photo, and added accessories based on the items it could identify in the image. It shows how the LLM used the reference image not only to create the action figure human in itself but also the all the other elements present in the generated image.\nAlthough it took a few tries to get my desired product with ChatGPT, the revision process progressed much more quickly than I had originally imagined and it was interesting to see how the LLM would take my feedback and incorpate it into the next image. I was especially curious to see how different each generation would look like and how much ‚Äòinspiration‚Äô it would keep or incorporate into the next generated image. I see now that each image seems to be developed quite independently from one another, keeping only the basic instructions I gave consistent. This was a fun learning experience!"
  },
  {
    "objectID": "posts/=--005_Dresscode/LLM_Dresscode.html",
    "href": "posts/=--005_Dresscode/LLM_Dresscode.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?"
  },
  {
    "objectID": "posts/=--005_Dresscode/LLM_Dresscode.html#a-visualization-problem-for-llms",
    "href": "posts/=--005_Dresscode/LLM_Dresscode.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?"
  },
  {
    "objectID": "posts/000_test_post-Copy1-Copy1/index.html",
    "href": "posts/000_test_post-Copy1-Copy1/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post-Copy1-Copy1/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post-Copy1-Copy1/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/003_LLM_Madlib/Untitled.html",
    "href": "posts/003_LLM_Madlib/Untitled.html",
    "title": "Mad Libs with LLMs: Is it the same?",
    "section": "",
    "text": "A pig in Ohio was arrested this morning after he frolicked a in front of Van Pelt. Ryan, had a history of slapping with a sandwich stuck in his elbow.\n‚ÄúI always thought he was round, but I never thought he‚Äôd do something like this. even his great-great-uncle was surprised.‚Äù\nAfter a brief dancing, cops followed him to a Wawa, where he reportedly scrapbooked in the fry machine.\nIn December, a woman was charged with a similar crime. But rather than bite with a hotdog, she hugged with a spiky dog.\nEither way, we imagine that after witnessing him clean with a hanger there are probably a whole lot of children that are going to need some therapy.\nSilly? Well, that was the product of a game of Mad Libs I played with my friend using this template:\n\n\n\n2b2c9c33f23e223cbb8cd2eb9f31f184.jpg\n\n\nAfter our little game, which really didn‚Äôt seem to have much logical flow, I wondered how LLMs would approach a Mad Libs prompt, especially when they are given the entire template itself. Will they be able to produce a coherent story, or will it be just as wacky as ours?\nTo answer my questions, I decided to record how my friend and I played another game of Mad Libs. This time, using this prompt below.\n\n\n\n295965cd20567dd3846e7b0c994315a5.jpg\n\n\nI was in charge of telling the story, and my friend filled in the blanks with words. Out came our masterpiece:\nHey, booboo bear. It‚Äôs me. What‚Äôs up? You know, Harry. Harry Potter. From the Quad. Two Sundays ago. I was the stubby guy in the purple parachute skirt. I paid the bus boy 1 dollars to nap me your information. I was wondering if maybe you‚Äôd like to fight out with me. Please don‚Äôt call the tend department. Alright, I‚Äôll nurse. So, that‚Äôs a no, right?\nNext, it was time to test the claude 3.5 LLM model. I gave it the prompt: ‚ÄúPlease finish this Mad Libs template I attached with the correct parts of speech. Make it as human as possible.‚Äù\nThis was the output:\nHey, sweetie. It‚Äôs me. What‚Äôs up? You know, Jake, Jake Anderson. From the library. Two Tuesdays ago. I was the nervous guy in the purple parachute pants. I paid the bus boy 50 dollars to tell me your information. I was wondering if maybe you‚Äôd like to hang out with me. Please don‚Äôt call the police department. Alright, I‚Äôll leave. So, that‚Äôs a no, right?\n\nIt‚Äôs very interesting to see that claude interpreted my request to make the output ‚Äúhuman‚Äù for Mad Libs as a way of making the result more coherent and logical. Claude‚Äôs output reads as if they had fully analyzed and understood the original template and chose words that would likely fit in with it deliberately. In my perspective, this would be the less ‚Äúhuman‚Äù output from this prompt as it makes too much sense for a game that is intended to be random. The coherence of the output really takes away from the humour and joy of this game.\nAnother aspect that makes claude‚Äôs output less appealing is that it doesn‚Äôt take the humour of my friend and I or the context in which we live in (our environment, pop culture, relevant news or information) into consideration into its chosen word bank for this experiment. This really makes the claude output seem outshined in comparison.\nThis little experiment with claude was worth trying, but if there‚Äôs one thing for sure, I won‚Äôt be asking claude to be finishing my Mad libs any time soon."
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/001_Personal_Color/Personal Color.html",
    "href": "posts/001_Personal_Color/Personal Color.html",
    "title": "My New Personal Color Analyst: ChatGPT",
    "section": "",
    "text": "Have you heard of seasonal color analysis? It‚Äôs become my answer to why I never why bright oranges and pinks because it always looked ‚Äúoff.‚Äù This recent social media trend is based on the science of color theory‚Äìthe magical wheel of color that the relationship between colors of one‚Äôs undertones and features can influence the way draped colors are perceived."
  },
  {
    "objectID": "posts/001_Personal_Color/Personal Color.html#the-output",
    "href": "posts/001_Personal_Color/Personal Color.html#the-output",
    "title": "My New Personal Color Analyst: ChatGPT",
    "section": "The Output",
    "text": "The Output\nThe output is as follows:\n\n\nStep 1: Undertone\nFrom your photos:\n\nYour skin has a neutral-to-warm undertone ‚Äî it doesn‚Äôt lean overly pink (cool) but also doesn‚Äôt look strictly golden/yellow (warm). It‚Äôs softly balanced.\nYou wear both gold and silver jewelry comfortably, but the gold tends to harmonize a little more.\n\n\n\n\nStep 2: Contrast Level\n\nYour hair is naturally dark, your eyes are softly defined, and your skin tone is light-medium.\nThis creates a medium contrast (not as high as Winter, but more than Summer).\n\n\n\n\nStep 3: Seasonal Family\n\nCool tones (like stark black or icy colors) look a bit harsh against your natural coloring.\nWarm tones (like soft peach, warm cream, light coral, and earthy shades) feel more harmonious.\nThe balance of warmth, softness, and medium contrast places you best in the Spring‚ÄìAutumn spectrum.\n\nLooking closely:\n\nYour skin glows more in clear, light, and fresh colors rather than deep, muted ones.\nSoft muted autumn shades (like olive, mustard, or deep rust) might overwhelm you, but lighter warms like coral, light turquoise, warm pink, and ivory seem flattering.\n\n\n‚úÖ Your Best Match: Light Spring\n\nUndertone: Warm-neutral\nDepth: Light to medium\nChroma: Clear, fresh, and bright\n\n\n\n\nBest Colors for You\n\nNeutrals: Warm ivory, light camel, soft beige, warm gray\nColors: Coral, peach, light periwinkle, warm turquoise, mint green, salmon pink, light sunny yellow\nAvoid: Harsh black, deep jewel tones (emerald, burgundy), or dusty muted shades (mauve, olive, taupe)"
  },
  {
    "objectID": "posts/001_Personal_Color/Personal Color.html#reflection",
    "href": "posts/001_Personal_Color/Personal Color.html#reflection",
    "title": "My New Personal Color Analyst: ChatGPT",
    "section": "Reflection",
    "text": "Reflection\nI have had many discussions with my sister and friends regarding my seasonal color palette, and the general consensus was that I was a warm-neutral tone that may be a spring or summer. ChatGPT was surprisingly accurate with this, and gave an output in congruence with them.\nI like how ChatGPT gave a breakdown of my undertone and contrast level before talking about my seasonal color as this is how many guides online are structured‚Äìlikely how ChatGPT was able to come to this conclusion in the first place. I wonder if LLMs like ChatGPT had more training and data focused on seasonal color analysis, they could become ‚Äúobjective measures‚Äù of the subjective fitting color season of an individual which draws out their natural undertone. Even with only three photos, it appears that ChatGPT gave accurate results. I suppose the next step would be for ChatGPT to analyze my closet, makeup, and jewelry to determine what is most harmonious to my features based on the data the system is fed.\nI‚Äôll walk away from this little experiment with a stronger affirmation of my light spring color season, which reinforces what I‚Äôve been assessed as before. And that means that you can spare your money for your trip to a local color analyst, because LLMs may just be our fashion experts at the comfort of our own homes."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is an experimental blog to understand and reflect on LLMs in healthcare and pop culture."
  }
]